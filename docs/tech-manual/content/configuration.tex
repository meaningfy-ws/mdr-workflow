\section{Configuration}
\label{sec:configuration}
	The deployment suite of micro-services is defined docker-compose.yml file. At deployment and at runtime, the service configurations are provided through OS environment variables available in the \textit{.env} file. The role of the .env file is to enable the system administrators to easily change default configurations as necessary in the context of their environment.

    The suite of micro-services is built, started and shut down via docker-compose, a tool designed especially for managing multi-container Docker applications, by describing them in a single file. Then, with a single command, you create and build, start or stop all the services using that configuration file.
    
    In order to avoid hard coding parameters, docker-compose allows you to define them externally. You have the option to define them as operating system level environment variables or provide them in a single file, which is passed as a parameter to the docker-compose tool using the \textit{--env-file} command line argument. Having them in a single file makes much more sense and it is more pragmatic, as you can see and manage all parameters in one place, add the file to the version control system (the contents of the file will evolve and be in sync with the actual code) and have different files for different environments.
    
    The file is usually named \textit{.env} and contains all of the parameters that you want to be able to change and that you need to build and run the defined containers. 
    
    Having the parameters in an \textit{.env} file is very useful in a multitude of scenarios, where you would want to have different configurations for different environments where you might want to deploy. As a more specific example, consider a continuous delivery pipeline and the URLs and ports you want your containers to bind (or to connect) to. You thus can easily have two \textit{.env} files, one named \textit{test.env} and one named \textit{acceptance.env}. Each file would have the same declared variables, but with different values for each of the continuous delivery pipeline stage where it’s being deployed. The benefit is that you deploy and test/use the same containers/artifacts and are able to configure them, on the spot, according to the environment that they are integrated with.
    
    
    Let’s take, for example, the RDF Differ user interface Docker container, which is defined, in the \textit{docker-compose.yml} file as it follows:
\begin{lstlisting}[]
    rdf-differ-ui:
    	container_name: rdf-differ-ui
    	image: meaningfy/rdf-differ-ui:latest
    	ports:
    		- ${RDF_DIFFER_UI_PORT}:${RDF_DIFFER_UI_PORT}
    	env_file: .env
    	restart: always
    	networks:
    		- mydefault
\end{lstlisting}
    The variable used in the definition of this service is just one, \textbf{\textit{RDF\_DIFFER\_UI\_PORT}}. And the place where docker-compose will look for that variable is specified in the \textbf{\textit{env\_file: .env}} line.
    
    Now, if you look in the “.env” file, you will quickly see that the variable is defined as \textbf{\textit{RDF\_DIFFER\_UI\_PORT=8030}}. Change the value of the port, rebuild the micro-services and RDF Differ will no longer be listening on 8030, but on the new port that you specified.
    
    
    This section describes the important configurations options available for each of the services.
	
	\subsection{RDF differ}
	
	The RDF differ application exposes an API and an UI and depends on a dedicated triple store. the RDF diff API is the core service providing the RDF diffing functionality. The URL and port are described below, as well as the request timeout:
	
	\begin{longtable}[c]{@{}p{3.5cm}p{3.5cm}l@{}}
		\toprule
		Description & Value & Associated variable \\* \midrule
		\endfirsthead
		%
		\multicolumn{3}{c}%
		{{\bfseries Table \thetable\ continued from previous page}} \\
		\endhead
		%
		\bottomrule
		\endfoot
		%
		\endlastfoot
		%
		Service URL & http://rdf-differ-api & RDF\_DIFFER\_API\_LOCATION \\
		Service API port & 4030 & RDF\_DIFFER\_API\_PORT \\
		Is in debug mode & True & RDF\_DIFFER\_DEBUG \\
		Service UI port & 8030 & RDF\_DIFFER\_UI\_PORT \\
		Web server worker process timeout & 1200 & RDF\_DIFFER\_GUNICORN\_TIMEOUT \\* \bottomrule
		\caption{RDF differ configurations}
		\label{tab:my-table1}\\
	\end{longtable}

	Please note that the domain specified in in the URL is only available inside the Docker network and is not visible from the outside. Its purpose is to provide a named way for a service to connect to another service. 

		\subsubsection{Custom template configuration}
		The \textbf{default diff report} template resides in \\ \texttt{/usr/src/app/resources/templates/diff\_report}.

		The custom template functionality is implemented using \textbf{\href{https://docs.docker.com/storage/volumes/}{docker's volumes}} mechanism. This implementation has been chosen as it requires no code modifications from the end-user's side.
		
		An externally defined volume \texttt{rdf-differ-template} which will contain the externally defined template (i.e. the custom template), which in turn is coupled with the \texttt{rdf-differ-api} docker container to use when generating the reports. The coupling of the volume to the service container is done with the following statement, which is included in the default docker compose configuration. 

		\begin{lstlisting}[]
volumes:
- rdf-differ-template:${RDF_DIFFER_TEMPLATE_LOCATION}
		\end{lstlisting}

		The lines above map the custom template that has been copied to the docker volume with the internal location of the container which has been defined in the \texttt{.env} file.
		
		\texttt{RDF\_DIFFER\_TEMPLATE\_LOCATION} is an environment variable used in the internal implementation of the \texttt{rdf-differ} service. Because it is internal it was not mentioned in Table \ref{tab:my-table1}.
		
		To configure your own template you can copy the default report template and adjust it to your needs or design a new one from scratch. 
		The templates are written in \textit{Jinja2} templating language \citep{jinja2}. The data source access is facilitated through the \textit{eds4jinja2} library \citep{eds4jinja2}. If you are familiar with Jinja2 language a short introduction to how to use eds4jinja2 is available on the documentation page\footnote{\url{https://eds4jinja2.readthedocs.io/en/latest/}}. Also the default template can be seen as an example accessible in the repository\footnote{\url{https://github.com/meaningfy-ws/rdf-differ/tree/master/resources/templates/diff_report}}.
		 
		\subsubsection{Use the custom template}
		After you have your custom template, run the \texttt{make} command, indicating the location of your template through the \texttt{location} variable.
		\begin{lstlisting}[language=bash]
make location=<location to template> differ-set-report-template
		\end{lstlisting}

		\textbf{NOTE}: Make sure that the location specified ends with a trailing slash \texttt{/}, otherwise the command will not work propery and the templates will not be copied to the docker volume.

		Example:
		\begin{lstlisting}[language=bash]
make location=~/template/location/ differ-set-report-template
		\end{lstlisting}

		After this, restart the \texttt{rdf-differ-api} container for the effects to take place.

	
	\subsection{RDF differ dedicated triple store}
	
	RDF differ depends on a Fuseki triple store to calculate and persist the diffs. The available configurations are described below. 

	\begin{longtable}[c]{@{}p{4cm}p{2cm}l@{}}
		\toprule
		Description & Value & Associated variable \\* \midrule
		\endfirsthead
		%
		\multicolumn{3}{c}%
		{{\bfseries Table \thetable\ continued from previous page}} \\
		\endhead
		%
		\bottomrule
		\endfoot
		%
		\endlastfoot
		%
		Admin account password & admin & RDF\_DIFFER\_FUSEKI\_ADMIN\_PASSWORD \\
		User name & admin & RDF\_DIFFER\_FUSEKI\_USERNAME \\
		Password & admin & RDF\_DIFFER\_FUSEKI\_PASSWORD \\
		Folder where Fuseki stores data & ./data/diff & RDF\_DIFFER\_FUSEKI\_DATA\_FOLDER \\
		External port & 3030 & RDF\_DIFFER\_FUSEKI\_PORT \\
		Internal port & 3030 &  \\
		Additional arguments passed to JVM & -Xmx2g & RDF\_DIFFER\_FUSEKI\_JVM\_ARGS \\
		URL & http://rdf-differ-fuseki & RDF\_DIFFER\_FUSEKI\_LOCATION \\* \bottomrule
		\caption{RDF differ dedicated triple store configurations}
		\label{tab:my-table2}\\
	\end{longtable}
	
	\subsection{RDF fingerprinter}
	
	RDF fingerprinter application exposes an API and an UI. It is based on executing SPARQL queries on given data and therefore also needs a dedicated triple store service. 

	\begin{longtable}[c]{@{}p{3.8cm}p{3cm}l@{}}
		\toprule
		Description & Value & Associated variable \\* \midrule
		\endfirsthead
		%
		\multicolumn{3}{c}%
		{{\bfseries Table \thetable\ continued from previous page}} \\
		\endhead
		%
		\bottomrule
		\endfoot
		%
		\endlastfoot
		%
		Service UI domain & http://rdf-fingerprinter-ui & RDF\_FINGERPRINTER\_UI\_LOCATION \\
		Service UI port & 8020 & RDF\_FINGERPRINTER\_UI\_PORT \\
		Service API domain & http://rdf-fingerprinter-api & RDF\_FINGERPRINTER\_API\_LOCATION \\
		Service API port & 4020 & RDF\_FINGERPRINTER\_API\_PORT \\* \bottomrule
		\caption{RDF fingerprinter configuration}
		\label{tab:my-table7}\\
	\end{longtable}

	Please note that the URL is only available inside the same Docker network and is not visible from the outside. Its purpose is to provide a named way for a service to connect to another service.
	
	\subsubsection{Custom Template Configuration}
		The \textbf{default fingerprinter report} template resides in the python fingerprinter package: \href{https://github.com/meaningfy-ws/rdf-fingerprinter/tree/master/fingerprint_report_templates/fingerprint_report}{\texttt{rdf-fingerprinter}}.

		The custom template functionality is implemented using \textbf{\href{https://docs.docker.com/storage/volumes/}{docker's volumes}} mechanism. This implementation has been chosen as it requires no code modifications from the end-user's side.

		An externally defined volume \texttt{rdf-fingerprinter-template} which will contain the externally defined template (aka: the custom template), which in turn is coupled with the \texttt{rdf-fingerprinter-api} docker container to use when generating the reports. The coupling of the volume to the service container is done with the following statement, which is included in the default docker compose configuration. 
		
		\begin{lstlisting}[]
volumes:
- rdf-fingerprinter-template:${RDF_FINGERPRINTER_TEMPLATE_LOCATION}
		\end{lstlisting}

		\texttt{RDF\_FINGERPRINTER\_TEMPLATE\_LOCATION} is an environment variable used in the internal implementation of the \texttt{rdf-fingerprinter} service.

		The lines above map the custom template that has been copied to the docker volume with the internal location of the container which has been defined in the \texttt{.env} file.

		To configure your own template you can copy the default report template and adjust it to your needs or design a new one from scratch. 
		The templates are written in \textit{Jinja2} templating language \citep{jinja2}. The data source access is facilitated through the \textit{eds4jinja2} library \citep{eds4jinja2}. If you are familiar with Jinja2 language a short introduction to how to use eds4jinja2 is available on the documentation page\footnote{\url{https://eds4jinja2.readthedocs.io/en/latest/}}. Also the default template can be seen as an example accessible in the repository\footnote{\url{https://github.com/meaningfy-ws/rdf-fingerprinter/tree/master/fingerprint_report_templates/fingerprint_report}}.

		\subsubsection{Use the custom template}
		After you have your custom template, run the \texttt{make} command, indicating the location of your template through the \texttt{location} variable.
		\begin{lstlisting}[language=bash]
make location=<location to template> fingerprinter-set-report-template
		\end{lstlisting}

		\textbf{NOTE}: Make sure that the location specified ends with a trailing slash \texttt{/}, otherwise the command will not work propery and the templates will not be copied to the docker volume.

		Example:
		\begin{lstlisting}[language=bash]
make location=~/template/location/ fingerprinter-set-report-template
		\end{lstlisting}

		After this, restart the \texttt{rdf-fingerprinter-api} container for the effects to take place.


	\subsection{RDF fingerprinter dedicated triple store}
	
	Fuseki triple store is used as the supporting triple store for this service.
	The available configurations for the Fuseki are described below. 
	
	
	\begin{longtable}[c]{@{}p{4cm}p{2.5cm}l@{}}
		\toprule
		Description & Value & Associated variable \\* \midrule
		\endfirsthead
		%
		\multicolumn{3}{c}%
		{{\bfseries Table \thetable\ continued from previous page}} \\
		\endhead
		%
		\bottomrule
		\endfoot
		%
		\endlastfoot
		%
		Admin password & admin & \footnotesize RDF\_DIFFER\_FUSEKI\_ADMIN\_PASSWORD \\
		User name & admin & \footnotesize RDF\_FINGERPRINTER\_FUSEKI\_USERNAME \\
		Password & admin & \footnotesize RDF\_FINGERPRINTER\_FUSEKI\_PASSWORD \\
		Fuseki data folder & ./data & \footnotesize RDF\_FINGERPRINTER\_FUSEKI\_DATA\_FOLDER \\
		External port & 3020 & \footnotesize RDF\_FINGERPRINTER\_FUSEKI\_PORT \\
		Additional JVM arguments & -Xmx2g & \footnotesize RDF\_DIFFER\_FUSEKI\_JVM\_ARGS \\
		Service URL & http://rdf-differ-fuseki & \footnotesize RDF\_DIFFER\_FUSEKI\_LOCATION \\* \bottomrule
		\caption{RDF differ dedicated triple store configurations}
		\label{tab:my-table8}\\
	\end{longtable}

	
	\subsection{RDF validator}
	
	RDF validator application exposes an API and an UI and does not depend on any additional services as everything is encapsulated into the Docker image. The configuration options are summarised below. 
	
	\begin{longtable}[c]{@{}p{4cm}p{5cm}l@{}}
		\toprule
		Description & Value & Associated variable \\* \midrule
		\endfirsthead
		%
		\multicolumn{3}{c}%
		{{\bfseries Table \thetable\ continued from previous page}} \\
		\endhead
		%
		\bottomrule
		\endfoot
		%
		\endlastfoot
		%
		Service UI port & 8010 & VALIDATOR\_UI\_PORT \\
		URL & http://rdf-validarot-ui:8010 & RDF\_VALIDATOR\_UI\_URL \\
		Service API port & 4010 & VALIDATOR\_API\_PORT \\* \bottomrule
		\caption{RDF validator configurations}
		\label{tab:my-table3}\\
	\end{longtable}

	Note, when validating SPARQL endpoints, the fully qualified domain name of the machine must be specified. As a consequence, ``localhost'' domain will not work as expected.

	\subsubsection{Custom Template Configuration}
	The \textbf{default validator report} template resides in \\ \texttt{/usr/src/app/resources/templates/validator\_report}.

	The custom template functionality is implemented using \textbf{\href{https://docs.docker.com/storage/volumes/}{docker's volumes}} mechanism. This implementation has been chosen as it requires no code modifications from the end-user's side.
	
	An externally defined volume \texttt{rdf-validator-template} which will contain the externally defined template (aka: the custom template), which in turn is coupled with the \texttt{rdf-validator-api} docker container to use when generating the reports.  The coupling of the volume to the service container is done with the following statement, which is included in the default docker compose configuration. 

	\begin{lstlisting}[]
volumes:
- rdf-validator-template:${RDF_VALIDATOR_TEMPLATE_LOCATION}
	\end{lstlisting}

	\texttt{RDF\_VALIDATOR\_TEMPLATE\_LOCATION} is an environment variable used in the internal implementation of the \texttt{rdf-validator} service.

	The lines above map the custom template that has been copied to the docker volume with the internal location of the container which has been defined in the \texttt{.env} file.
	
	To configure your own template you can copy the default report template and adjust it to your needs or design a new one from scratch. 
	The templates are written in \textit{Jinja2} templating language \citep{jinja2}. The data source access is facilitated through the \textit{eds4jinja2} library \citep{eds4jinja2}. If you are familiar with Jinja2 language a short introduction to how to use eds4jinja2 is available on the documentation page\footnote{\url{https://eds4jinja2.readthedocs.io/en/latest/}}. Also the default template can be seen as an example accessible in the repository\footnote{\url{https://github.com/meaningfy-ws/rdf-validator-ws/tree/master/resources/templates/validator_report}}.
		
	\subsubsection{Use the custom template}
	After you have your custom template, run the \texttt{make} command, indicating the location of your template through the \texttt{location} variable.
	\begin{lstlisting}[language=bash]
make location=<location to template> validator-set-report-template
	\end{lstlisting}

	\textbf{NOTE}: Make sure that the location specified ends with a trailing slash \texttt{/}, otherwise the command will not work propery and the templates will not be copied to the docker volume.

	Example:
	\begin{lstlisting}[language=bash]
make location=~/template/location/ validator-set-report-template
	\end{lstlisting}

	After this, restart the \texttt{rdf-validator-api} container for the effects to take place.


	\subsection{Nginx server}
	
	Nginx is a web server and in this context it serves on the port 80 (default HTTP) a splash page. However it can be configured in the future to operate as a reverse proxy as it may be necessary in the deployed environment. No configurations are foreseen for this service at the moment. 
	
	\subsection{Jenkins automation server}
	
	Jenkins automation server can be used to orchestrate some workflows especially those that may be triggered by operations on the SVN common repository. Only the port configurations are foreseen at the moment through environment variables. Additional ones can be done by following the official Jenkins installation manual. 
	
	\begin{longtable}[c]{@{}p{4cm}p{5cm}l@{}}
		\toprule
		Description & Value & Associated variable \\* \midrule
		\endfirsthead
		%
		\multicolumn{3}{c}%
		{{\bfseries Table \thetable\ continued from previous page}} \\
		\endhead
		%
		Service UI portUI & 8080 & JENKINS\_UI\_PORT \\
		Agent port & 50000 & JENKINS\_AGENTS\_PORT \\* \bottomrule
		\caption{Jenkins automation server configurations}
		\label{tab:my-table4}\\
	\end{longtable}
	
	\subsection{LinkedPipes ETL services}
	
	LinkedPipes ETL is deployed as a set of four dockerised services: storage, executor, executor monitor and the user interface. Additionally a dedicated triple store is also considered and described in the next section. 
	
	LinekdPipes ETL services are configured with  (a) a set of environment variables to control the Docker containers and (b) a special configurations file (\textit{configurations.properties}), which is used natively by the LinkedPipes ETL components (running inside the container). This configurations file mirrors the  established environment variables enumerated below.

	
	\begin{longtable}[c]{@{}p{5cm}p{4cm}l@{}}
		\toprule
		Description & Value & Associated variable \\* \midrule
		\endfirsthead
		%
		\multicolumn{3}{c}%
		{{\bfseries Table \thetable\ continued from previous page}} \\
		\endhead
		%
		\bottomrule
		\endfoot
		%
		\endlastfoot
		%
		Storage service port & 8063 & LP\_ETL\_STORAGE\_PORT \\		
		Executor service port & 8065 & LP\_ETL\_EXECUTOR\_PORT \\
		Executor monitor service port & 8061 & LP\_ETL\_MONITOR\_PORT \\		
		Service UI port & 8060 & LP\_ETL\_PORT \\
		Service domain & http://localhost:8060 & LP\_ETL\_DOMAIN \\* \bottomrule
		\caption{LinkedPipes ETL services configurations}
		\label{tab:my-table5}\\
	\end{longtable}
	
	Note that it is important to change the LP\_ETL\_DOMAIN each time the deployment environment changes. If it runs locally please set the value to be \textit{http://localhost:8060}, otherwise if it runs on a dedicated domain, the variable value must be set accordingly. If this is not done, the services will run but will not be able to load any pipelines because of a mismatch between the domain in the pipeline URI (created by using the variable value) and the domain of the service host. 
	
	The special \textit{configuration.properties} file\footnote{\url{https://github.com/meaningfy-ws/mdr-workflow/blob/master/docker/linkedpipes-etl/configuration/configuration.properties}}, as mentioned above must be in synch with the port numbers of the environment variables. The meaning of these variables is explained on the LinkedPipes ETL website. They have been preconfigured, so that no changes are necessary there but of course they can be adjusted if needed. The native configuration file is available next to the \textit{docker-compose.yml} in the subfolder \textit{linkedpipes-etl/configuration}. The content of this file with descriptions of parameters as provided by the LinkedPipes ETL authors is available in the Section \ref{sec:appendinx1}. 	
	
	\subsection{LinkedPipes ETL dedicated triple store}
	
	LinkedPipes ETL dedicated triple store is provided as an operational space to support the ETL workflows. The configurations are minimal as indicated below. 
	
	\begin{longtable}[c]{@{}p{4cm}p{2cm}l@{}}
		\toprule
		Description & Value & Associated variable \\* \midrule
		\endfirsthead
		%
		\multicolumn{3}{c}%
		{{\bfseries Table \thetable\ continued from previous page}} \\
		\endhead
		%
		\bottomrule
		\endfoot
		%
		\endlastfoot
		%
		Admin password & admin & LP\_ETL\_FUSEKI\_ADMIN\_PASSWORD \\
		Additional arguments passed to JVM & -Xmx2g & LP\_ETL\_FUSEKI\_JVM\_ARGS \\
		Fuseki port & 3060 & LP\_ETL\_FUSEKI\_PORT \\* \bottomrule
		\caption{LinkedPipes ETL dedicated triple store configurations}
		\label{tab:my-table6}\\
	\end{longtable}
	
	\subsection{Camunda BPMN engine}

	Camunda BPMN engine is deployed as a stand alone service.  A minimal set of configurations are provided here and more advanced ones shall be performed following the official installation manual. 
	
 	\begin{longtable}[c]{@{}p{4cm}p{2cm}l@{}}
	 	\toprule
	 	Description & Value & Associated variable \\* \midrule
	 	\endfirsthead
	 	%
	 	\multicolumn{3}{c}%
	 	{{\bfseries Table \thetable\ continued from previous page}} \\
	 	\endhead
	 	%
	 	\bottomrule
	 	\endfoot
	 	%
	 	\endlastfoot
	 	%	 	
	 	Service UI port & 8080 & CAMUNDA\_UI\_PORT \\* \bottomrule
	 	\caption{Camnunda BPMN service configurations}
	 	\label{tab:my-table9}\\
	 \end{longtable}
	
	